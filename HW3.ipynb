{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598934aa",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861e02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import bs4\n",
    "import lxml\n",
    "import os\n",
    "import time\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3e3e5",
   "metadata": {},
   "source": [
    "# 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcb07a",
   "metadata": {},
   "source": [
    "## 1.1 Get the list of places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2893f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_url = \"https://www.atlasobscura.com\"\n",
    "page_url = \"https://www.atlasobscura.com/places?sort=likes_count\"\n",
    "initial_result = rq.get(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1eaa4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_places = []\n",
    "N = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe7bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.atlasobscura.com/places?page=219&sort=likes_count\n",
      "https://www.atlasobscura.com/places?page=269&sort=likes_count\n",
      "https://www.atlasobscura.com/places?page=319&sort=likes_count\n",
      "https://www.atlasobscura.com/places?page=369&sort=likes_count\n"
     ]
    }
   ],
   "source": [
    "for _ in range(N):\n",
    "    \n",
    "    if _ % 50 == 0: # print process\n",
    "        print(page_url)\n",
    "    \n",
    "    time.sleep(0.01) # sleep to avoid too many requests\n",
    "    result = rq.get(page_url)\n",
    "    soup = bs4.BeautifulSoup(result.text)\n",
    "    \n",
    "    # acess all 18 cards of the current page\n",
    "    cards = soup.find_all(\"div\", {\"class\": \"col-md-4 col-sm-6 col-xs-12\"})\n",
    "    # len(cards) = 18\n",
    "    \n",
    "    # only store the href for each card\n",
    "    page_urls = [card.find_all(\"a\", {\"class\": \"content-card content-card-place\"})[0].get('href') \n",
    "                 for card in cards]\n",
    "    \n",
    "    top_places.append(page_urls)\n",
    "    \n",
    "    # acess url for the next page from the \"next page\" button\n",
    "    next_page = soup.find_all(\"a\", {\"rel\": \"next\"})[0].get('href')\n",
    "    page_url = home_url + next_page\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90e376a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all urls to one .txt file\n",
    "with open(\"/home/enno/Documents/GitHub/G32HW3/htmls/places.txt\", 'w+') as f:\n",
    "    for page in top_places:\n",
    "        for place in page:\n",
    "            f.write(home_url + place + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21dc8e",
   "metadata": {},
   "source": [
    "## 1.2 Crawl places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and split urls in 400 sets of 18\n",
    "with open(\"/home/enno/Documents/GitHub/G32HW3/htmls/places.txt\", 'r+') as f:\n",
    "    top_places = np.array_split(f.readlines(), 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9e55661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for writing .html files for the set of urls for one page\n",
    "def crawl_places(urls_per_page,\n",
    "                 parent_dir=\"/home/enno/Documents/GitHub/G32HW3/htmls\",\n",
    "                 page_ix=1):\n",
    "    \n",
    "    # parameter parent_dir has to be set according to user specs\n",
    "    \n",
    "    # create folder\n",
    "    directory = f'page_{page_ix}'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "\n",
    "    for place_ref in urls_per_page:\n",
    "        place_ref = place_ref[:-1]\n",
    "        \n",
    "        time.sleep(5) # sleep to avoid too many requests error\n",
    "        page = rq.get(place_ref)\n",
    "        place_name = place_ref.split('/')[-1].replace('-', '_')\n",
    "        \n",
    "        print(place_name)\n",
    "\n",
    "        with open(f'{path}/{place_name}.html', 'wb+') as f:\n",
    "            f.write(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f87048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ix, page in enumerate(top_places[276:], start=273):\n",
    "    if ix % 25 == 0: print('Page', ix)\n",
    "    crawl_places(page, page_ix=ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5205e7",
   "metadata": {},
   "source": [
    "## 1.3  Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777a635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "path_to_file = '/home/enno/Documents/GitHub/G32HW3/htmls/page_1/city_hall_station.html'\n",
    "with open(path_to_file, 'rb') as f:\n",
    "    soup = bs4.BeautifulSoup(f.read(), 'lxml') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bdf35a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place_attributes(soup, tsv_dir):\n",
    "    placeName = str(soup.find_all('h1',{'class':'DDPage__header-title'})[0].contents[0])\n",
    "    placeTags = str(soup.find_all('div',{'class':'DDPage__header-place-location'})[0].contents[0].text).split(sep=',')\n",
    "    numPeopleVisited = int(soup.find_all('div', {'class':'title-md item-action-count'})[0].contents[0])\n",
    "    numPeopleWant = int(soup.find_all('div', {'class':'title-md item-action-count'})[-1].contents[0])\n",
    "    placeDesc = soup.find_all('div', {'class':'DDP__body-copy'})[0].text.strip()\n",
    "    placeShortDesc = soup.find_all('h3', {'class':'DDPage__header-dek'})[0].text\n",
    "    placeAddress = soup.find_all('address', {'class':'DDPageSiderail__address'})[0].contents[3].text.partition('\\n')[0]\n",
    "    list_Alt_Long = soup.find_all('address', {'class':'DDPageSiderail__address'})[0].contents[3].text\n",
    "    placeAlt = int(float(list_Alt_Long.split('\\n', 1)[1].split()[0].replace(',', ' ')))\n",
    "    placeLong = int(float(list_Alt_Long.split('\\n', 1)[1].split()[1].replace(',', ' ')))\n",
    "\n",
    "\n",
    "    placeEditors = soup.find_all('div', {'class':'js-editor-list hidden'})[0].text.split()\n",
    "    for elem in placeEditors:\n",
    "        if len(elem) == 1:\n",
    "            placeEditors.remove(elem)\n",
    "\n",
    "\n",
    "    placePubDate = soup.find_all('div', {'class':'DDPContributor__name'})[0].text.replace(',', ' ')\n",
    "    placePubDate = parser.parse(placePubDate).date() # %y-%m-%d\n",
    "\n",
    "    card_grids = soup.find_all('div', \n",
    "                               {'class': \"card-grid CardRecircSection__card-grid js-inject-gtm-data-in-child-links\"\n",
    "    })\n",
    "    second_card = card_grids[1]\n",
    "    third_card = card_grids[2]\n",
    "\n",
    "    placeRelatedPlaces = [button.get(\"data-place-title\") \n",
    "                          for button in second_card.find_all('div', \n",
    "                                                             {'class': 'Card__action-btns vue-js-been-there-everywhere-place'})]\n",
    "\n",
    "    placeRelatedLists = [related_list.text.strip()\n",
    "                         for related_list in third_card.find_all('h3', \n",
    "                                                                 {'class': 'Card__heading --content-card-v2-title js-title-content'})]\n",
    "    placeURL = soup.find_all('link', {'rel': \"canonical\"})[0].get('href')\n",
    "\n",
    "    df =pd.DataFrame({'placeName' : placeName, \n",
    "                      'placeTags' : [placeTags],\n",
    "                      'numPeopleVisited': numPeopleVisited,\n",
    "                      'numPeopleWant': numPeopleWant,\n",
    "                      'placeDesc': placeDesc,\n",
    "                      'placeShortDesc': placeShortDesc,\n",
    "                      'placeAddress': placeAddress, \n",
    "                      'placeAlt': placeAlt,\n",
    "                      'placeLong': placeLong,\n",
    "                      'placeEditors': [placeEditors],\n",
    "                      'placePubDate': placePubDate,\n",
    "                      'placeRelatedPlaces': [placeRelatedPlaces],\n",
    "                      'placeRelatedLists': [placeRelatedLists],\n",
    "                      'placeURL': placeURL})\n",
    "    \n",
    "    file_name = '_'.join(placeName.lower().split())\n",
    "    data = df.to_csv(f'{tsv_dir}{file_name}.tsv', sep=\"\\t\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8ed086c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21348/3137646865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_current_place\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mget_place_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_tsv_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21348/4083180898.py\u001b[0m in \u001b[0;36mget_place_attributes\u001b[0;34m(soup, tsv_dir)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mplaceEditors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'js-editor-list hidden'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplaceEditors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "path_to_html_dir = '/home/enno/Documents/GitHub/G32HW3/htmls/'\n",
    "path_to_tsv_dir = '/home/enno/Documents/GitHub/G32HW3/tsvs/'\n",
    "\n",
    "pages = sorted(os.listdir(path_to_html_dir), key=lambda dir_name: int(dir_name.split('_')[-1]))\n",
    "\n",
    "for current_page in pages:\n",
    "    path_to_current_page = os.path.join(path_to_html_dir, current_page)\n",
    "    places_per_page = os.listdir(path_to_current_page)\n",
    "    \n",
    "    for current_place in places_per_page:\n",
    "        path_to_current_place = os.path.join(path_to_current_page, current_place)\n",
    "        \n",
    "        with open(path_to_current_place, 'rb') as f:\n",
    "            soup = bs4.BeautifulSoup(f.read(), 'lxml') \n",
    "            get_place_attributes(soup, path_to_tsv_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe988623",
   "metadata": {},
   "source": [
    "## 7. Theoretical question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a064b8f",
   "metadata": {},
   "source": [
    "An imaginary university is interested in accepting some of the applicants for positions to study the Master of Data Science there. Unfortunately, only a few spots are available, so the university requires students to take some exams. Students are then admitted based on how well they perform on these exams. For students to determine whether they have been successfully accepted to the university, the university wants to create a ranking list that includes every student's first name, last name, and total average on its course webpage. Students should be ranked in the list based on their average points in descending order. For example, if two students have the same average punctuation, they should be sorted in ascending order using their first and last names. University will give you the students' information in 'ApplicantsInfo.txt', and you should provide them with the ranking list in another .txt file and name it as 'RankingList.txt' . Kindly help this university in preparing this ranking list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f8a5a",
   "metadata": {},
   "source": [
    "\n",
    "   1 Try solving the problem mentioned above using three different sorting algorithms (do not use any MapReduce algorithm). (Note: Built-in Python functions (like .mean, .sort, etc.) are not allowed to be used. You must implement the algorithms from scratch).\n",
    "   \n",
    "   2 What is the time complexity of each algorithm you have used?\n",
    "   \n",
    "   3 Evaluate the time taken for each of your implementations to answer the query stored in the ApplicantsInfo.txt file and visualize them.\n",
    "   \n",
    "   4 What is the most optimal algorithm, in your opinion, and why?\n",
    "   \n",
    "   5 Implement a sorting algorithm using MapReduce and compare it against the three algorithms previously implemented using the ApplicantsInfo.txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10000 #number of students  \n",
    "m=50 #number of exams\n",
    "f=open('ApplicantsInfo.txt','r')\n",
    "i=0\n",
    "Applic={} #we want to create a dict of students\n",
    "for line in f:\n",
    "    line=line.split()\n",
    "    if i==0: #skipping the first line because is the shape of the file\n",
    "        i=1\n",
    "    else:\n",
    "        if n!=0:\n",
    "            student=line[0]+' '+line[1]\n",
    "            Applic[student]=[int(x) for x in line[2:m+2]]\n",
    "            n-=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing an average function\n",
    "def Average(x):\n",
    "    aver=0\n",
    "    for i in x:\n",
    "        aver+=i\n",
    "    \n",
    "    return round(aver/len(x),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04955316",
   "metadata": {},
   "source": [
    "The running time of Average is $\\Theta(N)$ where N is the length of the input x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494948c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of lists with the averages for each student\n",
    "Rank=[]\n",
    "for name in [stud for stud in Applic.keys()]: \n",
    "    Rank.append([name,Average(Applic[name])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting algorithms for list of list\n",
    "#if h=1 it sorts by scores, if h=0 it sorts by names\n",
    "def InsertionSort(Rank,h): \n",
    "    \n",
    "    for i in range(1,len(Rank)):\n",
    "            temp= Rank[i]\n",
    "            j=i-1\n",
    "            while j>=0 and temp[h]>Rank[j][h]:\n",
    "                     Rank[j+1] = Rank[j]\n",
    "                     j-=1  \n",
    "            Rank[j+1] = temp\n",
    "    return Rank\n",
    "############################################\n",
    "def SelectionSort(Rank, h):\n",
    "    \n",
    "    for i in range(len(Rank)):\n",
    "        M = i\n",
    "        for j in range(i + 1,len(Rank)):\n",
    "            if Rank[j][h] > Rank[M][h]:\n",
    "                M = j\n",
    "        (Rank[i], Rank[M]) = (Rank[M], Rank[i])\n",
    "        \n",
    "    return Rank\n",
    "#############################################\n",
    "def BubbleSort(Rank,h):\n",
    "    change = 0\n",
    "    for i in range(len(Rank)-1):\n",
    "        for j in range(0, len(Rank)-i-1):\n",
    "            if Rank[j][h] < Rank[j+1][h]:\n",
    "                change = 1\n",
    "                (Rank[j], Rank[j+1]) = (Rank[j+1], Rank[j])\n",
    "        if change==0:\n",
    "            return Rank\n",
    "    return Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193bb0c4",
   "metadata": {},
   "source": [
    "All of those algorithms have running time of $\\Theta(N^2)$ where N is the length of the array in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c335bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the Applicants\n",
    "import timeit \n",
    "unsorted=Rank.copy() #we want to keep the unsorted list to compare this non MapReduced algorithm with the MapReduced one\n",
    "Times=[]\n",
    "for Alg in [1,2,3]: # 1: InsertionSort, 2: SelectionSort, 3:BubbleSort\n",
    "    Rank=unsorted.copy()\n",
    "    start=timeit.default_timer() #this is to evaluate the time required to run the algorithm\n",
    "    #sorting by exams averages\n",
    "    if Alg==1:\n",
    "        Rank=InsertionSort(Rank,1)\n",
    "    elif Alg==2:\n",
    "        Rank=SelectionSort(Rank,1)\n",
    "    elif Alg==3:\n",
    "        Rank=BubbleSort(Rank,1)\n",
    "        \n",
    "    #sorting duplicates by names\n",
    "    i=0 \n",
    "    while i <= (len(Rank)-1):\n",
    "        j=1\n",
    "        while (i+j)<(len(Rank)-1) and Rank[i][1]==Rank[i+j][1]: #to know the length of consecutive elements that have same score\n",
    "            j+=1\n",
    "        if j!=1: \n",
    "            #temp variable to store the correct order (we used [::-1] to sort in ascending order)\n",
    "            if Alg==1:\n",
    "                temp=InsertionSort([Rank[i+k] for k in range(j)],0)[::-1] \n",
    "            elif Alg==2:\n",
    "                temp=SelectionSort([Rank[i+k] for k in range(j)],0)[::-1]\n",
    "            if Alg==3:\n",
    "                temp=BubbleSort([Rank[i+k] for k in range(j)],0)[::-1]\n",
    "            for k in range(j):\n",
    "                Rank[i+k]=temp[k] #changing the order in the Rank\n",
    "            i+=j #just to skip the elements already changed\n",
    "        else:\n",
    "            i+=1\n",
    "\n",
    "    stop=timeit.default_timer()\n",
    "    Times.append(stop-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625987a6",
   "metadata": {},
   "source": [
    "The running time to sort the duplicate is, in the worst case (i.e. all the scores are the same), equal to the running time of the sort method we use to sort by names so it is $\\Theta(N^2)$.\n",
    "\n",
    "So we have that to sort the Rank vector, in the worst case, we need a running time of $\\Theta(2N^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac48acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the running times of each algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('seconds')\n",
    "plt.xlabel('Sorting Alg')\n",
    "plt.bar([1,2,3],Times)\n",
    "plt.show()\n",
    "Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7b2ce",
   "metadata": {},
   "source": [
    "As we can see, the InsertionSort algorithm is the best one of the non MapReduced algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a MapReduced algorithm to confront the running times\n",
    "\n",
    "def MergeSort(Rank,h):\n",
    "    \n",
    "    if len(Rank) == 1:\n",
    "        return Rank\n",
    "\n",
    "    l = len(Rank) // 2\n",
    "    left = MergeSort(Rank[:l],h)\n",
    "    right = MergeSort(Rank[l:],h)\n",
    "    return merge(left, right,h)\n",
    "#####################################\n",
    "def merge(left, right,h):\n",
    "    merged = []\n",
    "    i = 0 \n",
    "    j=0\n",
    "    \n",
    "    while i < len(left) and j < len(right):\n",
    "        if left[i][h] > right[j][h]:\n",
    "            merged.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            merged.append(right[j])\n",
    "            j += 1\n",
    "    merged.extend(left[i:])\n",
    "    merged.extend(right[j:])\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=unsorted #because the Rank list was already sorted by previous codes so I'll assign back the unsorted one\n",
    "start=timeit.default_timer()\n",
    "#sorting Rank by scores\n",
    "Rank=MergeSort(Rank,1)\n",
    "#sorting duplicates by names (Reusing previous algorithm)\n",
    "i=0 \n",
    "while i <= (len(Rank)-1):\n",
    "        j=1\n",
    "        while (i+j)<(len(Rank)-1) and Rank[i][1]==Rank[i+j][1]: #to know the length of consecutive elements that have same score\n",
    "            j+=1\n",
    "        if j!=1: \n",
    "            #temp variable to store the correct order (we used [::-1] to sort in ascending order)\n",
    "            temp=MergeSort([Rank[i+k] for k in range(j)],0)[::-1] \n",
    "           \n",
    "            for k in range(j):\n",
    "                Rank[i+k]=temp[k] #changing the order in the Rank\n",
    "            i+=j #just to skip the elements already changed\n",
    "        else:\n",
    "            i+=1\n",
    "stop=timeit.default_timer()\n",
    "Times.append(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the running times\n",
    "plt.ylabel('seconds')\n",
    "plt.xlabel('Sorting Alg')\n",
    "plt.bar([1,2,3,4],Times)\n",
    "plt.show()\n",
    "Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef20dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOP TEN STUDENTS\n",
    "assert len(Rank)>=10\n",
    "\n",
    "for i in range(10):\n",
    "    print(Rank[i][0]+' '+str(Rank[i][1]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceee9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "F=open('RankingList.txt','w') #creating a .txt file with the sorted Applicants\n",
    "for i in range(len(Rank)):\n",
    "    F.write(Rank[i][0]+' '+str(Rank[i][1])+'\\n')\n",
    "F.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
